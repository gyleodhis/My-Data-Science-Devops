{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35021453",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "Models are a representation of things. They are not the things themselves. Models must be based on empirical observations (data)\n",
    "__Generalization__ is key for supervised machine learning models. The model should avoid __high bias (underfitting)__ and __high variance (Overfitting)__ but should rather be __Just right (The Goldilocks model)\n",
    "1. Underfittng - Uses two parameters, usually a straing line and does not capture most of the data points.\n",
    "2. Overfitting - Uses five parameters (4th order polynomial). It goes through every single data point.\n",
    "3. The Goldilock - Uses three parameters (Third order polynomial often called the parabola.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36935e29",
   "metadata": {},
   "source": [
    "Model testing through __Cross-Validation__ reduces the generalization error\n",
    "We take all out training data and use it for training. Most people use five fold cross validation. But 10 fold can be used if the dataset is huge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc573158",
   "metadata": {},
   "source": [
    "#### Bias - Variance Trade off\n",
    "This is ideally minimizing the generalization error - Which means minimizing the error between the training sample and the test sample.\n",
    "- To avaoid overffiting you need to know when to stop training the model. Although the training set error may be decreasing you may be simply overfitting the training data.\n",
    "- To test this apply the model to a validation data set (that is not part of the training set). If the validation data set error starts to diverge from the training set error then you will know that you have an overfit model and its time to stop the training.\n",
    "- Where then do you stop exactly. Stop training where the generalization error is the smallest. That is the error between your training set error and validation set error is smallest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcf42c7",
   "metadata": {},
   "source": [
    "## Supervised Learning Concepts\n",
    "- Data collection --> Formulation of a hypothesis --> Deduction (formulation of a predictive test) --> Experimental design and testing --> Evaluation --> REview of results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca72c077",
   "metadata": {},
   "source": [
    "### Star - Galaxy theory\n",
    "if radius < 6 then star, otherwise galaxy. Then:\n",
    "- __True Positive (TP)__: A star correctly identified as a star\n",
    "- __True Negative (TN)__: A galaxy correctly identified.\n",
    "- __False Positive (FP)__: a galaxy classified as a star.\n",
    "- __False Negative (FN)__: A star classified as galaxy\n",
    "\n",
    "__Accuracy__ is now the error estimation as is calculated as:\n",
    "accuracy = (TP+TN)total otherwise known as the F1 - score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4d325e",
   "metadata": {},
   "source": [
    "### Measures of Accuracy\n",
    "- Overall accuracy  = (TP + TN)/total\n",
    "- Producers accuracy = TP/(TP+FN) or TN/(TN + FP)\n",
    "- User's accuracy = TP/(TP+FP) or TN/(TN+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ced89b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
